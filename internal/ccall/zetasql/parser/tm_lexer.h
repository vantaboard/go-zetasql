// generated by Textmapper; DO NOT EDIT

#ifndef STORAGE_GOOGLESQL_PARSERLEXER_H_
#define STORAGE_GOOGLESQL_PARSERLEXER_H_


#include <cstdint>
#include <ostream>

#include "absl/strings/string_view.h"
#include "googlesql/parser/tm_token.h"
#include "googlesql/parser/parser_mode.h"
#include "googlesql/public/parse_location.h"
#include "googlesql/common/errors.h"
#include "absl/strings/escaping.h"

namespace googlesql::parser {
inline constexpr absl::string_view bomSeq = "\xef\xbb\xbf";

class Lexer {
 public:

using Location = ::googlesql::ParseLocationRange;
  explicit Lexer(absl::string_view input_source ABSL_ATTRIBUTE_LIFETIME_BOUND);

  // Next finds and returns the next token in source. The stream end is
  // indicated by Token.EOI.
  //
  // The token text can be retrieved later by calling the Text() method.
  ABSL_MUST_USE_RESULT Token Next();

  // Location of the last token returned by Next().
  ABSL_MUST_USE_RESULT Location LastTokenLocation() const {
    return Location(ParseLocationPoint::FromByteOffset(filename_, token_offset_), ParseLocationPoint::FromByteOffset(filename_, offset_))
;
  }
  // LastTokenLine returns the line number of the last token returned by Next()
  // (1-based).
  ABSL_MUST_USE_RESULT int64_t LastTokenLine() const { return token_line_; }

  // Text returns the substring of the input corresponding to the last token.
  ABSL_MUST_USE_RESULT absl::string_view Text() const
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return source_.substr(token_offset_, offset_ - token_offset_);
  }


 private:
  // Rewind can be used in lexer actions to accept a portion of a scanned token,
  // or to include more text into it.
  void Rewind(int64_t rewind_offset);

  absl::string_view source_;

  int32_t input_rune_ = 0;    // current character, -1 means end of input
  int64_t offset_ = 0;        // character offset
  int64_t token_offset_ = 0;  // last token byte offset
  int64_t line_ = 1;          // current line number (1-based)
  int64_t token_line_ = 1;    // last token line
  int64_t scan_offset_ = 0;   // scanning byte offset


  void SetOverrideError(const ParseLocationRange& location,
                        absl::string_view error_message) {
    override_error_ = MakeSqlErrorAtPoint(location.start()) << error_message;
  }

  void SetUnclosedError(absl::string_view kind) {
    SetOverrideError(LastTokenLocationWithStartOffset(),
                     /*error_message=*/absl::StrCat("Syntax error: Unclosed ",
                                                    kind));
  }

  void SetTripleUnclosedError(absl::string_view kind) {
    SetUnclosedError(/*kind=*/absl::StrCat("triple-quoted ", kind));
  }

  // Similar to LastTokenLocation(), but the start and end offsets are adjusted
  // to account for the fact that the lexer is initialized with a substring of
  // the input.
  Location LastTokenLocationWithStartOffset() const {
    Location location = LastTokenLocation();
    location.mutable_start().SetByteOffset(location.start().GetByteOffset() +
                                           start_offset_);
    location.mutable_end().SetByteOffset(location.end().GetByteOffset() +
                                         start_offset_);
    return location;
  }

  // Stores the error countered during lexing.
  absl::Status override_error_;

  // The input filename.
  absl::string_view filename_;

  // This is the additional offset to be added to the start and end offsets
  // of the tokens returned by LastTokenLocationWithStartOffset() to account for
  // the fact that the lexer is initialized with a substring of the input.
  //
  // `start_offset_` can be non-zero when parsing multiple statements. For
  // example,
  //
  // ```
  // SELECT 1;
  // SELECT 2;
  // ```
  //
  // A new lexer is created for each statement, so for "SELECT 2;", the
  // `start_offset_` is 10 and `input_source_` is "SELECT 2;", i.e. just the
  // substring. As a result, when `start_offset_` is not zero, line numbers are
  // not with respect to the entire input, but with respect to the substring
  // "SELECT 2;", and should not be used directly in the error messages.
  //
  // Using the function Rewind() can make sure the line numbers and the offsets
  // stay consistent w.r.t. the entire input, but its time complexity is O(n)
  // where n is the input length, making the parser time complexity become
  // O(n^2).
  int start_offset_ = 0;

  friend class GoogleSqlTokenizer;
};

inline std::ostream& operator<<(std::ostream& os, const Lexer& lexer) {
  return os << "googlesql::parser::Lexer at line " << lexer.LastTokenLine() << " location "
            << lexer.LastTokenLocation() << " last token was \""
            << lexer.Text() << "\"";
}

}  // namespace googlesql::parser

#endif  // STORAGE_GOOGLESQL_PARSERLEXER_H_
